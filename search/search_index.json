{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ArXiv Contrastive Embeddings","text":"<p>Fine tune Sentence Transformers models on arXiv titles and abstracts to produce embeddings that cluster papers by primary subject and power similarity search.</p>"},{"location":"#project-summary","title":"Project summary","text":"<p>We build pair datasets from arXiv metadata for contrastive learning, fine tune sentence transformer models across multiple backbones, and evaluate semantic retrieval alongside embedding-based classification. The system builds a FAISS similarity search index, supports ONNX Runtime for faster inference paths, and serves embeddings behind a FastAPI endpoint for downstream apps and retrieval services.</p> <p>The pipeline starts by downloading and splitting the arXiv dataset, then builds contrastive pairs from primary subjects. We train sentence transformers with the selected loss, evaluate precision@k alongside classifier metrics, compare TF-IDF baselines, export ONNX models, and build a FAISS index before serving embeddings through the API.</p>"},{"location":"#get-started","title":"Get started","text":"<p>This repository uses uv for package and project management. <pre><code>uv sync --dev\nuv run python src/mlops_project/data.py\nuv run python src/mlops_project/train.py\n</code></pre></p>"},{"location":"#key-docs","title":"Key docs","text":"<p>Start with Data and preprocessing, then follow Training and Evaluation. Deployment details live in API and deployment, and configuration lives in Configuration.</p>"},{"location":"api/","title":"API and deployment","text":""},{"location":"api/#service-usage","title":"Service usage","text":"<p>The API serves normalized embeddings for abstracts using FastAPI.</p> <pre><code>flowchart LR\n  A[Client] --&gt; B[Post embed]\n  B --&gt; C[FastAPI app]\n  C --&gt; D[SentenceTransformer model]\n  D --&gt; E[Normalize embeddings]\n  E --&gt; F[JSON response]</code></pre>"},{"location":"api/#endpoints","title":"Endpoints","text":"<p>The API exposes <code>GET /health</code> for service status and device info, and <code>POST /embed</code> to accept <code>{ \"abstract\": \"...\" }</code> and return embedding data.</p>"},{"location":"api/#request-and-response","title":"Request and response","text":"<p>Request body: <pre><code>{ \"abstract\": \"...\" }\n</code></pre></p> <p>Response body: <pre><code>{ \"embedding_dim\": 384, \"embedding\": [0.01, 0.02] }\n</code></pre></p> <p>Empty or whitespace abstracts return <code>400</code>, and missing fields return <code>422</code>.</p> <p>Example request: <pre><code>curl -X POST http://localhost:8000/embed \\\n  -H \"Content-Type: application/json\" \\\n  -d \"{\\\"abstract\\\": \\\"Graph neural networks for molecule property prediction.\\\"}\"\n</code></pre></p>"},{"location":"api/#model-loading","title":"Model loading","text":"<p>The API loads a model from <code>--model-path</code>, then <code>MODEL_PATH</code>, and falls back to <code>models/contrastive-minilm/</code>. The model directory must exist and contain a SentenceTransformer model. GPU is used when available.</p>"},{"location":"api/#run-locally","title":"Run locally","text":"<p>Run the service with Uvicorn: <pre><code>MODEL_PATH=\"models/all-MiniLM-L6-v2-mnrl-100k-balanced\" uv run uvicorn src.mlops_project.api:app \\\n  --host 0.0.0.0 --port 8000\n</code></pre></p>"},{"location":"api/#deployment-and-containers","title":"Deployment and containers","text":""},{"location":"api/#docker-image","title":"Docker image","text":"<p>Build and run the inference container: <pre><code>docker build -f dockerfiles/api.dockerfile -t mlops-api:latest .\ndocker run --rm -p 8000:8000 \\\n  -v ${PWD}/models:/app/models \\\n  -e MODEL_PATH=/app/models/all-MiniLM-L6-v2-mnrl-100k-balanced \\\n  mlops-api:latest\n</code></pre></p>"},{"location":"api/#gpu-notes","title":"GPU notes","text":"<p>If you run on Linux with NVIDIA drivers, add <code>--gpus all</code> to the container run command.</p>"},{"location":"api/#deployment-pipeline","title":"Deployment pipeline","text":"<p>Cloud Build (<code>cloudbuild.yaml</code>) publishes the training image on the <code>build</code> branch after CI checks pass. See Cloud Build for configuration details. The API image is built locally from <code>dockerfiles/api.dockerfile</code> unless you add a dedicated CI workflow.</p>"},{"location":"api/#onnx-runtime","title":"ONNX runtime","text":"<p>ONNX export and inference are supported via <code>mlops_project.model</code> with ONNX Runtime. Use the exported ONNX model for CPU-friendly deployments or batch inference workflows.</p>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#config-files","title":"Config files","text":"<p>Training and preprocessing use Hydra config files in <code>configs/</code>.</p> <p>Key files include <code>configs/dataset.yaml</code>, <code>configs/train_config.yaml</code>, and <code>configs/gpu_train_vertex.yaml</code> for the Vertex AI custom job spec.</p> <p>Here is a typical dataset configuration: <pre><code># configs/dataset.yaml\nsource: nick007x/arxiv-papers\nsplits:\n  test_size: 0.2\n  seed: 42\npairs:\n  num_train: 100000\n  num_eval: 10000\n  loss: MultipleNegativesRankingLoss\n  balanced: true\n  text_field: abstract\n</code></pre></p> <p>And here is a typical training configuration: <pre><code># configs/train_config.yaml\nmeta:\n  save_model: true\n  use_gcs: false\n  bucket_name: mlops-proj\n  require_cuda: true\ntrain:\n  epochs: 1\n  batch_size: 256\n  loss: MultipleNegativesRankingLoss\n  model: all-MiniLM-L6-v2\nwandb:\n  enabled: true\n</code></pre></p>"},{"location":"configuration/#override-examples","title":"Override examples","text":"<pre><code>uv run python src/mlops_project/train.py train.batch_size=128 train.loss=ContrastiveLoss\nuv run python src/mlops_project/data.py pairs.num_train=50000 pairs.balanced=false\n</code></pre>"},{"location":"data/","title":"Data and preprocessing","text":"<p>This page explains the dataset fields, split strategy, and pair generation used in training.</p>"},{"location":"data/#dataset-and-splits","title":"Dataset and splits","text":"<p>The project uses the Hugging Face dataset <code>nick007x/arxiv-papers</code> and loads it with datasets. We rely on <code>primary_subject</code> for contrastive labels, <code>subjects</code> for metadata, and <code>abstract</code> plus <code>title</code> as text inputs.</p> <p><code>preprocess</code> creates train, eval, and test splits and stores them under <code>data/</code> in datasets format. The split ratios and seed live in <code>configs/dataset.yaml</code> and are managed via Hydra.</p>"},{"location":"data/#pairs-and-preprocessing-workflow","title":"Pairs and preprocessing workflow","text":"<p>Two pair building strategies are supported: <code>create_positive_pairs</code> for <code>MultipleNegativesRankingLoss</code> with anchor/positive pairs, and <code>create_contrastive_pairs</code> for <code>ContrastiveLoss</code> with sentence pairs and labels.</p> <p>The <code>balanced</code> flag controls whether subjects are sampled uniformly or weighted by frequency.</p>"},{"location":"data/#preprocessing-flow","title":"Preprocessing flow","text":"<p>The diagram below shows how the raw dataset becomes saved splits and pair datasets. <pre><code>flowchart TD\n  A[Load dataset] --&gt; B[Select columns]\n  B --&gt; C[Split train eval test]\n  C --&gt; D[Save splits to data]\n  C --&gt; E[Build train pairs]\n  C --&gt; F[Build eval pairs]\n  E --&gt; G[Save train pairs]\n  F --&gt; H[Save eval pairs]\n  D --&gt; I[Save preprocess config]\n  G --&gt; I\n  H --&gt; I</code></pre></p> <p>Run preprocessing <pre><code>uv run python src/mlops_project/data.py\n</code></pre></p> <p>Override defaults with Hydra: <pre><code>uv run python src/mlops_project/data.py pairs.loss=ContrastiveLoss pairs.num_train=200000 pairs.balanced=false\n</code></pre></p> <p>Alternative module entrypoint: <pre><code>uv run python -m mlops_project.data\n</code></pre></p> <p>Output artifacts After preprocessing you should see <code>data/train</code>, <code>data/eval</code>, <code>data/test</code>, plus <code>data/train_pairs</code>, <code>data/eval_pairs</code>, and <code>data/preprocess_config.yaml</code> for reproducibility checks.</p> <p><code>ensure_data_exists</code> will re-run preprocessing if the saved config no longer matches the requested config.</p>"},{"location":"evaluation/","title":"Evaluation","text":"<p>This page summarizes how we evaluate retrieval, classification, baselines, and similarity search.</p>"},{"location":"evaluation/#retrieval-metrics","title":"Retrieval metrics","text":"<p>Evaluation uses <code>InformationRetrievalEvaluator</code> with precision at k (1, 5, 10). The evaluator samples a subset of the test dataset (default 5000), uses 20 percent of samples as queries and the rest as corpus, and computes precision at k on subject-aligned relevance sets.</p> <p>Training evaluates every 500 steps and logs metrics to stdout and Weights &amp; Biases when enabled.</p>"},{"location":"evaluation/#embedding-classifier","title":"Embedding classifier","text":"<p>We train a lightweight logistic regression classifier on frozen embeddings with scikit-learn. Report accuracy, macro F1, and per class metrics to quantify how well embeddings separate subject categories.</p>"},{"location":"evaluation/#baselines-and-model-comparisons","title":"Baselines and model comparisons","text":"<p>Baseline comparisons include TF-IDF features with scikit-learn plus logistic regression. We also compare multiple transformer backbones to quantify the tradeoffs between model size, training time, and retrieval/classification quality.</p>"},{"location":"evaluation/#similarity-search","title":"Similarity search","text":"<p>We build a FAISS index over normalized embeddings to support fast similarity search. Cosine similarity is implemented as inner product on unit normalized vectors, which aligns with the training objective.</p>"},{"location":"evaluation/#custom-evaluation","title":"Custom evaluation","text":"<p>You can build an evaluator directly: <pre><code>from mlops_project.evaluate import create_ir_evaluator\nfrom mlops_project.data import ArxivPapersDataset\n\ndataset = ArxivPapersDataset(\"test\").dataset\nevaluator = create_ir_evaluator(dataset, sample_size=2000)\n</code></pre></p>"},{"location":"ops/","title":"MLOps stack","text":"<p>This page covers the data, experiment, and deployment tooling that keeps the project reproducible.</p>"},{"location":"ops/#ops-stack","title":"Ops stack","text":"<p>DVC tracks datasets, <code>data.dvc</code> pins state, and <code>.dvc/config</code> points to the GCS remote. Experiment tracking is handled through Weights &amp; Biases and controlled by <code>wandb.enabled</code>, which can be disabled for offline runs or CI. We ship Docker images for training and inference using <code>dockerfiles/train.dockerfile</code> and <code>dockerfiles/api.dockerfile</code>.</p>"},{"location":"ops/#automation-and-cloud","title":"Automation and cloud","text":"<p>GitHub Actions runs formatting, linting, type checking, and tests on every push to <code>master</code>. The build job submits <code>cloudbuild.yaml</code> to Cloud Build to publish the training image.</p> <p><code>configs/gpu_train_vertex.yaml</code> describes a Vertex AI custom job for GPU training. Combine it with the Cloud Build image to run managed training jobs.</p>"},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#goals-and-scope","title":"Goals and scope","text":"<p>This project fine tunes Sentence Transformers models on arXiv titles and abstracts so that papers from the same primary subject are close in embedding space, while unrelated subjects move apart. The learned embeddings support semantic retrieval, similarity search, and embedding-based classification.</p>"},{"location":"overview/#end-to-end-flow","title":"End-to-end flow","text":"<pre><code>flowchart TD\n  A[ArXiv dataset] --&gt; B[Preprocess and split]\n  B --&gt; C[Pair generation]\n  C --&gt; D[Train sentence transformer]\n  B --&gt; G[TF IDF baseline]\n  D --&gt; E[Retrieval eval precision at k]\n  D --&gt; F[Embedding classifier logistic regression]\n  D --&gt; H[Export ONNX]\n  D --&gt; I[Build FAISS index]\n  D --&gt; J[API service]\n  J --&gt; K[Embed and health endpoints]</code></pre> <p>Implemented end-to-end covers preprocessing and pair generation, training with retrieval evaluation, and lightweight classification with TF-IDF baselines.</p> <p>We build similarity search indexes with FAISS, export ONNX for ONNX Runtime inference alongside Sentence Transformers, and serve embeddings via a FastAPI service with <code>/health</code> and <code>/embed</code>. Dockerized training and inference run through CI checks, and we compare larger transformer backbones.</p>"},{"location":"overview/#inputs-outputs-and-components","title":"Inputs, outputs, and components","text":"<p>Inputs are the <code>title</code> and <code>abstract</code> fields plus subject labels (<code>primary_subject</code>, <code>subjects</code>). Outputs include trained embedding models and ONNX exports, pair datasets for contrastive learning, retrieval and classification metrics with baseline reports, API-ready artifacts, and similarity search indexes built with FAISS.</p> <p>Core components tie those pieces together. Preprocessing splits data and builds pairs, training runs with <code>SentenceTransformerTrainer</code> and losses such as <code>MultipleNegativesRankingLoss</code> or <code>ContrastiveLoss</code>, and evaluation uses <code>InformationRetrievalEvaluator</code> for precision@k.</p> <p>Downstream tasks cover classifiers, TF-IDF baselines, similarity search over normalized embeddings, ONNX export with ONNX Runtime, and a FastAPI service that returns normalized embeddings.</p>"},{"location":"overview/#technology-stack-and-dependencies","title":"Technology stack and dependencies","text":"<p>The stack below is grouped by purpose so you can scan what powers training, serving, and operations at a glance.</p>"},{"location":"overview/#core-runtime","title":"Core runtime","text":"Area Tools Training and acceleration PyTorch, Accelerate Modeling Transformers, Sentence Transformers Data Datasets Config Hydra Serving FastAPI, Uvicorn Tracking Weights &amp; Biases Versioning DVC with dvc-gdrive Search and inference FAISS, ONNX Runtime Baselines scikit-learn Utilities Loguru, Requests, Invoke, Typer Notebooks Jupyter"},{"location":"overview/#dev-quality-and-docs","title":"Dev, quality, and docs","text":"Area Tools Testing pytest, coverage Linting and typing ruff, mypy Automation pre-commit Docs MkDocs, MkDocs Material, mkdocstrings <p>Tooling uses uv as the package manager and command runner in all examples.</p>"},{"location":"project-structure/","title":"Project structure","text":"<pre><code>.\n|-- .dvc/                       # DVC settings and remotes\n|-- .github/                    # GitHub Actions workflows and Dependabot\n|   |-- dependabot.yaml\n|   `-- workflows/\n|       |-- lint-test-build.yaml\n|       `-- pre-commit-update.yaml\n|-- configs/                    # Hydra config files\n|   |-- dataset.yaml\n|   |-- gpu_train_vertex.yaml\n|   `-- train_config.yaml\n|-- data/                       # Versioned datasets (DVC)\n|-- dockerfiles/                # Training and API containers\n|   |-- api.dockerfile\n|   `-- train.dockerfile\n|-- docs/                       # Documentation sources\n|   |-- README.md\n|   `-- source/\n|       |-- api.md\n|       |-- configuration.md\n|       |-- data.md\n|       |-- evaluation.md\n|       |-- index.md\n|       |-- ops.md\n|       |-- overview.md\n|       |-- project-structure.md\n|       |-- quickstart.md\n|       |-- reference.md\n|       |-- tags.md\n|       |-- training.md\n|       |-- reference/\n|       |   `-- api.md\n|       `-- stylesheets/\n|           `-- extra.css\n|-- models/                     # Trained model artifacts\n|-- notebooks/                  # Exploration notebooks\n|-- outputs/                    # Training outputs and logs\n|-- reports/                    # Reports and figures\n|-- src/\n|   `-- mlops_project/\n|       |-- __init__.py\n|       |-- api.py\n|       |-- data.py\n|       |-- evaluate.py\n|       |-- model.py\n|       |-- train.py\n|       |-- utils.py\n|       `-- visualize.py\n|-- tests/                      # Unit tests\n|   |-- conftest.py\n|   |-- test_api.py\n|   |-- test_data.py\n|   `-- test_model.py\n|-- cloudbuild.yaml\n|-- data.dvc\n|-- mkdocs.yaml\n|-- pyproject.toml\n|-- README.md\n|-- tasks.py\n`-- uv.lock\n</code></pre>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#setup-and-data","title":"Setup and data","text":"<p>This repository uses uv for package and project management. Start by syncing dependencies: <pre><code>uv sync --dev\n</code></pre></p> <p>Then preprocess the data to create dataset splits and pair datasets under <code>data/</code>: <pre><code>uv run python src/mlops_project/data.py\n</code></pre></p>"},{"location":"quickstart/#train-and-serve","title":"Train and serve","text":"<p>Train a model with the default config: <pre><code>uv run python src/mlops_project/train.py\n</code></pre></p> <p>If you want to run on CPU or tweak a parameter, override the config on the CLI: <pre><code>uv run python src/mlops_project/train.py meta.require_cuda=false train.batch_size=64 train.epochs=1\n</code></pre></p> <p>Run the embedding API with Uvicorn serving FastAPI: <pre><code>MODEL_PATH=\"models/all-MiniLM-L6-v2-mnrl-100k-balanced\" uv run uvicorn src.mlops_project.api:app \\\n  --host 0.0.0.0 --port 8000\n</code></pre></p>"},{"location":"quickstart/#validate-and-iterate","title":"Validate and iterate","text":"<p>Run the test suite with pytest: <pre><code>uv run pytest tests/\n</code></pre></p> <p>Serve docs locally with MkDocs: <pre><code>uv run mkdocs serve -f mkdocs.yaml\n</code></pre></p>"},{"location":"reference/","title":"Python API","text":"<p>This page contains the auto-generated API reference for the Python modules in <code>src/mlops_project</code>.</p>"},{"location":"reference/#modules","title":"Modules","text":""},{"location":"reference/#mlops_project-data","title":"mlops_project.data","text":""},{"location":"reference/#mlops_project.data","title":"mlops_project.data","text":""},{"location":"reference/#mlops_project.data.ArxivPapersDataset","title":"ArxivPapersDataset","text":"<p>Arxiv papers dataset from Hugging Face.</p>"},{"location":"reference/#mlops_project.data.ArxivPapersDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(index: int) -&gt; dict\n</code></pre> <p>Return a given sample from the dataset.</p>"},{"location":"reference/#mlops_project.data.ArxivPapersDataset.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return the length of the dataset.</p>"},{"location":"reference/#mlops_project.data.create_contrastive_pairs","title":"create_contrastive_pairs","text":"<pre><code>create_contrastive_pairs(\n    dataset,\n    num_pairs: int = 100000,\n    text_field: str = \"abstract\",\n    seed: int = 42,\n    balanced: bool = True,\n)\n</code></pre> <p>Create positive and negative pairs for ContrastiveLoss.</p> <p>Returns a dataset with columns: sentence1, sentence2, label - label=1.0 for positive pairs (same subject) - label=0.0 for negative pairs (different subjects)</p> <p>Parameters:</p> Name Type Description Default <code>balanced</code> <code>bool</code> <p>If True, each subject has equal probability of being chosen.       If False, subjects are weighted by their frequency in the dataset.</p> <code>True</code>"},{"location":"reference/#mlops_project.data.create_pairs","title":"create_pairs","text":"<pre><code>create_pairs(\n    dataset,\n    pair_fn: Callable,\n    save_path: Path,\n    num_pairs: int,\n    text_field: str = \"abstract\",\n    seed: int = 42,\n    balanced: bool = True,\n) -&gt; Dataset\n</code></pre> <p>Create and save pairs to disk.</p>"},{"location":"reference/#mlops_project.data.create_positive_pairs","title":"create_positive_pairs","text":"<pre><code>create_positive_pairs(\n    dataset,\n    num_pairs: int = 100000,\n    text_field: str = \"abstract\",\n    seed: int = 42,\n    balanced: bool = True,\n)\n</code></pre> <p>Create positive pairs for MultipleNegativesRankingLoss.</p> <p>Returns a dataset with columns: anchor, positive Each pair contains two abstracts from papers with the same primary_subject. MNRL will use in-batch negatives automatically.</p> <p>Parameters:</p> Name Type Description Default <code>balanced</code> <code>bool</code> <p>If True, each subject has equal probability of being chosen.       If False, subjects are weighted by their frequency in the dataset.</p> <code>True</code>"},{"location":"reference/#mlops_project.data.ensure_data_exists","title":"ensure_data_exists","text":"<pre><code>ensure_data_exists(\n    data_dir: Path,\n    dataset_config: DictConfig | ListConfig | None = None,\n) -&gt; None\n</code></pre> <p>Run preprocessing if required data doesn't exist or config has changed.</p>"},{"location":"reference/#mlops_project.data.load_pairs","title":"load_pairs","text":"<pre><code>load_pairs(load_path: Path) -&gt; Dataset\n</code></pre> <p>Load pairs from disk.</p>"},{"location":"reference/#mlops_project.data.preprocess","title":"preprocess","text":"<pre><code>preprocess(\n    loss: LossType = LossType.MultipleNegativesRankingLoss,\n    output_folder: Path = Path(\"data\"),\n    test_size: float = 0.2,\n    number_of_pairs: int = 1000000,\n    number_of_eval_pairs: int = 10000,\n    seed: int = 42,\n    source: str = \"nick007x/arxiv-papers\",\n    columns: list[str] | None = None,\n    text_field: str = \"abstract\",\n    balanced: bool = True,\n) -&gt; None\n</code></pre> <p>Download and preprocess the arxiv papers dataset.</p>"},{"location":"reference/#mlops_project.data.preprocess_hydra","title":"preprocess_hydra","text":"<pre><code>preprocess_hydra(config: DictConfig | ListConfig) -&gt; None\n</code></pre> <p>Hydra entry point for preprocessing.</p>"},{"location":"reference/#mlops_project-model","title":"mlops_project.model","text":""},{"location":"reference/#mlops_project.model","title":"mlops_project.model","text":""},{"location":"reference/#mlops_project-evaluate","title":"mlops_project.evaluate","text":""},{"location":"reference/#mlops_project.evaluate","title":"mlops_project.evaluate","text":""},{"location":"reference/#mlops_project.evaluate.create_ir_evaluator","title":"create_ir_evaluator","text":"<pre><code>create_ir_evaluator(\n    dataset,\n    sample_size: int = 5000,\n    name: str = \"arxiv-retrieval\",\n)\n</code></pre> <p>Create an Information Retrieval evaluator for precision@k metrics.</p>"},{"location":"reference/#mlops_project-train","title":"mlops_project.train","text":""},{"location":"reference/#mlops_project.train","title":"mlops_project.train","text":""},{"location":"reference/#mlops_project-utils","title":"mlops_project.utils","text":""},{"location":"reference/#mlops_project.utils","title":"mlops_project.utils","text":""},{"location":"reference/#mlops_project.utils.build_output_dir_name","title":"build_output_dir_name","text":"<pre><code>build_output_dir_name(\n    model: str, loss: str, num_pairs: int, balanced: bool\n) -&gt; str\n</code></pre> <p>Build output directory name from config values.</p>"},{"location":"reference/#mlops_project.utils.format_num_pairs","title":"format_num_pairs","text":"<pre><code>format_num_pairs(n: int) -&gt; str\n</code></pre> <p>Format number of pairs for output directory name.</p>"},{"location":"reference/#mlops_project-visualize","title":"mlops_project.visualize","text":""},{"location":"reference/#mlops_project.visualize","title":"mlops_project.visualize","text":""},{"location":"reference/#api-module","title":"API module","text":"<p>The FastAPI module performs model loading at import time, which is not friendly to auto documentation. See API and deployment for endpoint and runtime details.</p>"},{"location":"tags/","title":"Tags","text":"<p>Browse tags used across the documentation. Tags will appear here as they are added to pages.</p>"},{"location":"training/","title":"Training","text":""},{"location":"training/#training-pipeline","title":"Training pipeline","text":"<p>Training runs from <code>src/mlops_project/train.py</code> and is configured via Hydra using <code>configs/train_config.yaml</code>.</p> <p>The training run validates CUDA availability when <code>meta.require_cuda=true</code>, ensures the dataset and pairs exist (and preprocesses if needed), loads training and evaluation pairs, instantiates the SentenceTransformer model, and then trains with <code>SentenceTransformerTrainer</code> while evaluating precision@k during training.</p> <p>Key configuration options include <code>train.model</code> (default <code>all-MiniLM-L6-v2</code>), <code>train.loss</code> set to <code>MultipleNegativesRankingLoss</code> or <code>ContrastiveLoss</code>, and the usual training controls like <code>train.batch_size</code>, <code>train.epochs</code>, <code>train.warmup_ratio</code>, and <code>train.seed</code>. Use <code>meta.save_model</code> to toggle checkpoint saving, and <code>meta.use_gcs</code> plus <code>meta.bucket_name</code> to load and save to GCS paths. Disable Weights &amp; Biases logging with <code>wandb.enabled=false</code> for offline runs.</p>"},{"location":"training/#run-training-and-outputs","title":"Run training and outputs","text":"<pre><code>uv run python src/mlops_project/train.py\n</code></pre> <p>Override parameters: <pre><code>uv run python src/mlops_project/train.py train.loss=ContrastiveLoss train.epochs=3 wandb.enabled=false\n</code></pre></p>"},{"location":"training/#docker-cuda","title":"Docker + CUDA","text":"<p>Requires Docker with NVIDIA GPU support.</p> <p>Build the CUDA training image: <pre><code>docker build -f dockerfiles/train.dockerfile -t mlops-train:cuda .\n</code></pre></p> <p>Run training on GPU with mounted volumes: <pre><code>docker run --rm --gpus all \\\n  -v ${PWD}/data:/app/data \\\n  -v ${PWD}/models:/app/models \\\n  mlops-train:cuda uv run python src/mlops_project/train.py\n</code></pre></p> <p>Disable W&amp;B logging: <pre><code>docker run --rm --gpus all \\\n  -v ${PWD}/data:/app/data \\\n  -v ${PWD}/models:/app/models \\\n  mlops-train:cuda uv run python src/mlops_project/train.py wandb.enabled=false\n</code></pre></p> <p>Models are saved under <code>models/&lt;model&gt;-&lt;loss&gt;-&lt;pairs&gt;-&lt;balanced&gt;</code> when <code>meta.save_model=true</code>. Logs stream to stdout and <code>train.log</code> via Loguru.</p>"},{"location":"reference/api/","title":"API module notes","text":"<p>The FastAPI app lives in <code>src/mlops_project/api.py</code> and loads a SentenceTransformer model at import time. That behavior is not friendly to auto documentation, so this module is documented manually.</p>"},{"location":"reference/api/#entry-points","title":"Entry points","text":"<p>The API reads configuration from the CLI flag <code>--model-path</code>, then falls back to the <code>MODEL_PATH</code> environment variable, and finally defaults to <code>models/contrastive-minilm/</code>.</p>"},{"location":"reference/api/#endpoints","title":"Endpoints","text":"<p>The service exposes <code>GET /health</code> to report status and device, and <code>POST /embed</code> to return normalized embeddings for an abstract.</p>"},{"location":"reference/api/#runtime-notes","title":"Runtime notes","text":"<p>The model loads once on startup and normalizes embeddings to unit length. GPU is used when available. ONNX export and inference are supported via <code>mlops_project.model</code> and ONNX Runtime.</p> <p>See API and deployment for usage and deployment details.</p>"}]}