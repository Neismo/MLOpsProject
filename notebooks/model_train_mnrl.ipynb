{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728845dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PAIRS = int(1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "check-gpu",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 2039695\n",
      "Test samples: 509924\n",
      "Columns: ['primary_subject', 'subjects', 'abstract', 'title']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "from mlops_project.data import ArxivPapersDataset\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "data_dir = Path(\"../data\")\n",
    "train_dataset = ArxivPapersDataset(split=\"train\", data_dir=data_dir).dataset\n",
    "test_dataset = ArxivPapersDataset(split=\"test\", data_dir=data_dir).dataset\n",
    "\n",
    "print(f\"Train samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Columns: {train_dataset.column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "create-pairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached pairs from ../data/train_pairs_mnrl\n",
      "\n",
      "Training pairs: 100000\n",
      "{'anchor': 'The paper describes the project, implementation and test of a C-band (5GHz) Low Noise Amplifier (LNA) using new low noise Pseudomorphic High Electron Mobility Transistors (pHEMTS) from Avago. The amplifier was developed to be used as a cost effective solution in a receiver chain for Galactic Emission Mapping (GEM-P) project in Portugal with the objective of finding affordable solutions not requiring strong cryogenic operation, as is the case of massive projects like the Square Kilometer Array (SKA), in Earth Sensing projects and other niches like microwave reflectometry. The particular application and amplifier requirements are first introduced. Several commercially available low noise devices were selected and the noise performance simulated. An ultra-low noise pHEMT was used for an implementation that achieved a Noise Figure of 0.6 dB with 13 dB gain at 5 GHz. The design, simulation and measured results of the prototype are presented and discussed.', 'positive': 'The image degradation produced by atmospheric turbulence and optical aberrations is usually alleviated using post-facto image reconstruction techniques, even when observing with adaptive optics systems. These techniques rely on the development of the wavefront using Zernike functions and the non-linear optimization of a certain metric. The resulting optimization procedure is computationally heavy. Our aim is to alleviate this computationally burden. To this aim, we generalize the recently developed extended Zernike-Nijboer theory to carry out the analytical integration of the Fresnel integral and present a natural basis set for the development of the point spread function in case the wavefront is described using Zernike functions. We present a linear expansion of the point spread function in terms of analytic functions which, additionally, takes defocusing into account in a natural way. This expansion is used to develop a very fast phase-diversity reconstruction technique which is demonstrated through some applications. This suggest that the linear expansion of the point spread function can be applied to accelerate other reconstruction techniques in use presently and based on blind deconvolution.'}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from datasets import Dataset, load_from_disk\n",
    "\n",
    "def create_positive_pairs(dataset, num_pairs: int = 100000, text_field: str = \"abstract\", seed: int = 42):\n",
    "    \"\"\"\n",
    "    Create positive pairs for MultipleNegativesRankingLoss.\n",
    "    \n",
    "    Returns a dataset with columns: anchor, positive\n",
    "    Each pair contains two abstracts from papers with the same primary_subject.\n",
    "    MNRL will use in-batch negatives automatically.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    subject_to_indices = defaultdict(list)\n",
    "    for idx, subject in enumerate(dataset[\"primary_subject\"]):\n",
    "        subject_to_indices[subject].append(idx)\n",
    "    \n",
    "    subjects = [s for s in subject_to_indices.keys() if len(subject_to_indices[s]) >= 2]\n",
    "    print(f\"Found {len(subjects)} subjects with 2+ samples\")\n",
    "    \n",
    "    pairs = {\"anchor\": [], \"positive\": []}\n",
    "    \n",
    "    print(f\"Creating {num_pairs} positive pairs...\")\n",
    "    for _ in range(num_pairs):\n",
    "        subject = random.choice(subjects)\n",
    "        idx1, idx2 = random.sample(subject_to_indices[subject], 2)\n",
    "        pairs[\"anchor\"].append(dataset[idx1][text_field])\n",
    "        pairs[\"positive\"].append(dataset[idx2][text_field])\n",
    "    \n",
    "    return Dataset.from_dict(pairs)\n",
    "\n",
    "def load_or_create_pairs(dataset, save_path: Path, num_pairs: int, text_field: str = \"abstract\", seed: int = 42):\n",
    "    if save_path.exists():\n",
    "        print(f\"Loading cached pairs from {save_path}\")\n",
    "        return load_from_disk(str(save_path))\n",
    "    \n",
    "    print(f\"Creating new pairs (will be cached at {save_path})\")\n",
    "    pairs = create_positive_pairs(dataset, num_pairs=num_pairs, text_field=text_field, seed=seed)\n",
    "    pairs.save_to_disk(str(save_path))\n",
    "    return pairs\n",
    "\n",
    "train_pairs_path = data_dir / \"train_pairs_mnrl\"\n",
    "train_pairs = load_or_create_pairs(train_dataset, train_pairs_path, num_pairs=NUM_PAIRS)\n",
    "print(f\"\\nTraining pairs: {len(train_pairs)}\")\n",
    "print(train_pairs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "create-eval-pairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached pairs from ../data/eval_pairs_mnrl\n",
      "Evaluation pairs: 10000\n"
     ]
    }
   ],
   "source": [
    "eval_pairs_path = data_dir / \"eval_pairs_mnrl\"\n",
    "eval_pairs = load_or_create_pairs(test_dataset, eval_pairs_path, num_pairs=10000, seed=123)\n",
    "print(f\"Evaluation pairs: {len(eval_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "create-evaluator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IR Evaluator: 998 queries, 5000 corpus docs\n",
      "IR Evaluator created for precision@k metrics\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator\n",
    "\n",
    "def create_ir_evaluator(dataset, sample_size: int = 5000, name: str = \"arxiv-retrieval\"):\n",
    "    np.random.seed(42)\n",
    "    indices = np.random.choice(len(dataset), min(sample_size, len(dataset)), replace=False)\n",
    "    \n",
    "    queries = {}\n",
    "    corpus = {}\n",
    "    relevant_docs = {}\n",
    "    subject_to_corpus_ids = defaultdict(set)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        idx = int(idx)\n",
    "        corpus_id = f\"doc_{i}\"\n",
    "        corpus[corpus_id] = dataset[idx][\"abstract\"]\n",
    "        subject = dataset[idx][\"primary_subject\"]\n",
    "        subject_to_corpus_ids[subject].add(corpus_id)\n",
    "    \n",
    "    query_indices = indices[:sample_size // 5]\n",
    "    \n",
    "    for i, idx in enumerate(query_indices):\n",
    "        idx = int(idx)\n",
    "        query_id = f\"query_{i}\"\n",
    "        queries[query_id] = dataset[idx][\"abstract\"]\n",
    "        subject = dataset[idx][\"primary_subject\"]\n",
    "        doc_id = f\"doc_{i}\"\n",
    "        relevant_docs[query_id] = subject_to_corpus_ids[subject] - {doc_id}\n",
    "    \n",
    "    queries = {qid: q for qid, q in queries.items() if len(relevant_docs.get(qid, set())) > 0}\n",
    "    relevant_docs = {qid: docs for qid, docs in relevant_docs.items() if qid in queries}\n",
    "    \n",
    "    print(f\"IR Evaluator: {len(queries)} queries, {len(corpus)} corpus docs\")\n",
    "    \n",
    "    return InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=name,\n",
    "        precision_recall_at_k=[1, 5, 10],\n",
    "        show_progress_bar=True,\n",
    "    )\n",
    "\n",
    "ir_evaluator = create_ir_evaluator(test_dataset, sample_size=5000)\n",
    "print(\"IR Evaluator created for precision@k metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baseline-eval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Baseline Precision@k (before fine-tuning) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40683c58e95e432585ae37debc57917a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051eb7175d2a4f77aace5fb9eab6a9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:02<00:00,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv-retrieval_cosine_precision@1: 0.0000\n",
      "arxiv-retrieval_cosine_precision@5: 0.3741\n",
      "arxiv-retrieval_cosine_precision@10: 0.3905\n",
      "arxiv-retrieval_cosine_recall@1: 0.0000\n",
      "arxiv-retrieval_cosine_recall@5: 0.0323\n",
      "arxiv-retrieval_cosine_recall@10: 0.0620\n",
      "arxiv-retrieval_cosine_ndcg@10: 0.3473\n",
      "arxiv-retrieval_cosine_mrr@10: 0.3461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Baseline Precision@k (before fine-tuning) ===\")\n",
    "baseline_results = ir_evaluator(model)\n",
    "for key, value in baseline_results.items():\n",
    "    if \"precision\" in key or \"recall\" in key or \"mrr\" in key or \"ndcg\" in key:\n",
    "        print(f\"{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-trainer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f66f1b06b441148f4a3a851757f822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized with MNRL loss. Ready to train!\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformerTrainer, SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.losses import MultipleNegativesRankingLoss\n",
    "\n",
    "training_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=\"../models/mnrl-minilm\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    learning_rate=3e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    eval_on_start=True,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    torch_compile=torch.cuda.is_available(),\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    tf32=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# MultipleNegativesRankingLoss uses in-batch negatives\n",
    "loss = MultipleNegativesRankingLoss(model)\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_pairs,\n",
    "    eval_dataset=eval_pairs,\n",
    "    loss=loss,\n",
    "    evaluator=ir_evaluator,\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized with MNRL loss. Ready to train!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "train",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mthorhojhus\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/thorh/MLOpsProject/notebooks/wandb/run-20260109_150650-w7cgvxgn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/thorhojhus/sentence-transformers/runs/w7cgvxgn' target=\"_blank\">curious-energy-5</a></strong> to <a href='https://wandb.ai/thorhojhus/sentence-transformers' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/thorhojhus/sentence-transformers' target=\"_blank\">https://wandb.ai/thorhojhus/sentence-transformers</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/thorhojhus/sentence-transformers/runs/w7cgvxgn' target=\"_blank\">https://wandb.ai/thorhojhus/sentence-transformers/runs/w7cgvxgn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='782' max='782' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [782/782 03:29, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Arxiv-retrieval Cosine Accuracy@1</th>\n",
       "      <th>Arxiv-retrieval Cosine Accuracy@3</th>\n",
       "      <th>Arxiv-retrieval Cosine Accuracy@5</th>\n",
       "      <th>Arxiv-retrieval Cosine Accuracy@10</th>\n",
       "      <th>Arxiv-retrieval Cosine Precision@1</th>\n",
       "      <th>Arxiv-retrieval Cosine Precision@5</th>\n",
       "      <th>Arxiv-retrieval Cosine Precision@10</th>\n",
       "      <th>Arxiv-retrieval Cosine Recall@1</th>\n",
       "      <th>Arxiv-retrieval Cosine Recall@5</th>\n",
       "      <th>Arxiv-retrieval Cosine Recall@10</th>\n",
       "      <th>Arxiv-retrieval Cosine Ndcg@10</th>\n",
       "      <th>Arxiv-retrieval Cosine Mrr@10</th>\n",
       "      <th>Arxiv-retrieval Cosine Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.641879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.656313</td>\n",
       "      <td>0.795591</td>\n",
       "      <td>0.883768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373747</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032296</td>\n",
       "      <td>0.061957</td>\n",
       "      <td>0.347124</td>\n",
       "      <td>0.346205</td>\n",
       "      <td>0.183550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.585600</td>\n",
       "      <td>2.600233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.680361</td>\n",
       "      <td>0.780561</td>\n",
       "      <td>0.867735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402405</td>\n",
       "      <td>0.436774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038716</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>0.387305</td>\n",
       "      <td>0.352894</td>\n",
       "      <td>0.278644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8245f796b84a4e8cd92bc71cdddf70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a437ca430a402a9dd774e6caae6873",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:02<00:00,  2.60s/it]\n",
      "W0109 15:09:17.981000 23123 torch/fx/experimental/symbolic_shapes.py:6823] [0/2] _maybe_guard_rel() was called on non-relation expression Eq(s47, s8) | Eq(s8, 1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0162c0957364611be99c6d77ed82842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84a063b8c4164f17bd881545444b2b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:02<00:00,  2.64s/it]\n",
      "W0109 15:10:30.290000 23123 torch/fx/experimental/symbolic_shapes.py:6823] [0/3] _maybe_guard_rel() was called on non-relation expression Eq(s47, s8) | Eq(s8, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=782, training_loss=2.6874484479274896, metrics={'train_runtime': 237.0431, 'train_samples_per_second': 421.864, 'train_steps_per_second': 3.299, 'total_flos': 0.0, 'train_loss': 2.6874484479274896, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "final-eval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Precision@k (after fine-tuning) ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3189257f527448e8a9d8847c8562cce0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0870a74c3ba0433ab0e1faeb1492a1dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:02<00:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv-retrieval_cosine_precision@1: 0.0000\n",
      "arxiv-retrieval_cosine_precision@5: 0.4136\n",
      "arxiv-retrieval_cosine_precision@10: 0.4480\n",
      "arxiv-retrieval_cosine_recall@1: 0.0000\n",
      "arxiv-retrieval_cosine_recall@5: 0.0417\n",
      "arxiv-retrieval_cosine_recall@10: 0.0836\n",
      "arxiv-retrieval_cosine_ndcg@10: 0.3978\n",
      "arxiv-retrieval_cosine_mrr@10: 0.3576\n",
      "\n",
      "=== Improvement ===\n",
      "arxiv-retrieval_cosine_precision@1: +0.0000\n",
      "arxiv-retrieval_cosine_precision@5: +0.0395\n",
      "arxiv-retrieval_cosine_precision@10: +0.0575\n",
      "arxiv-retrieval_cosine_ndcg@10: +0.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Precision@k (after fine-tuning) ===\")\n",
    "final_results = ir_evaluator(model)\n",
    "for key, value in final_results.items():\n",
    "    if \"precision\" in key or \"recall\" in key or \"mrr\" in key or \"ndcg\" in key:\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n=== Improvement ===\")\n",
    "for key in baseline_results:\n",
    "    if \"precision\" in key or \"ndcg\" in key:\n",
    "        improvement = final_results[key] - baseline_results[key]\n",
    "        print(f\"{key}: {improvement:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "save-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models/mnrl-minilm-finetuned\n"
     ]
    }
   ],
   "source": [
    "model.save(\"../models/mnrl-minilm-finetuned\")\n",
    "print(\"Model saved to ../models/mnrl-minilm-finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-project (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
