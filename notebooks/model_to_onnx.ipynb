{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Output paths (relative to this notebook: ../models)\n",
    "notebook_dir = Path.cwd()\n",
    "models_dir = notebook_dir.parent / \"models\"\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Trained model directory from train.py output\n",
    "trained_model_dir = models_dir / \"contrastive-minilm\"\n",
    "onnx_path = models_dir / \"arxiv-all-MiniLM-L6-v2.onnx\"\n",
    "\n",
    "model = SentenceTransformer(str(trained_model_dir))\n",
    "model.eval()\n",
    "model.to(\"cpu\")\n",
    "\n",
    "dummy = model.tokenize([\"This is a dummy input\"])\n",
    "input_ids = dummy[\"input_ids\"]\n",
    "attention_mask = dummy[\"attention_mask\"]\n",
    "token_type_ids = dummy.get(\"token_type_ids\")\n",
    "\n",
    "class OnnxWrapper(torch.nn.Module):\n",
    "    def __init__(self, st_model: SentenceTransformer, use_token_type_ids: bool):\n",
    "        super().__init__()\n",
    "        self.st_model = st_model\n",
    "        self.use_token_type_ids = use_token_type_ids\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids=None):\n",
    "        features = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "        if self.use_token_type_ids:\n",
    "            features[\"token_type_ids\"] = token_type_ids\n",
    "        outputs = self.st_model(features)\n",
    "        return outputs[\"sentence_embedding\"]\n",
    "\n",
    "use_token_type_ids = token_type_ids is not None\n",
    "wrapper = OnnxWrapper(model, use_token_type_ids)\n",
    "wrapper.eval()\n",
    "\n",
    "input_names = [\"input_ids\", \"attention_mask\"]\n",
    "inputs = (input_ids, attention_mask)\n",
    "dynamic_axes = {\n",
    "    \"input_ids\": {0: \"batch\", 1: \"sequence\"},\n",
    "    \"attention_mask\": {0: \"batch\", 1: \"sequence\"},\n",
    "    \"sentence_embedding\": {0: \"batch\"},\n",
    "}\n",
    "\n",
    "if use_token_type_ids:\n",
    "    input_names.append(\"token_type_ids\")\n",
    "    inputs = (input_ids, attention_mask, token_type_ids)\n",
    "    dynamic_axes[\"token_type_ids\"] = {0: \"batch\", 1: \"sequence\"}\n",
    "\n",
    "print(f\"Exporting ONNX model to: {onnx_path}\")\n",
    "\n",
    "torch.onnx.export(\n",
    "    wrapper,\n",
    "    inputs,\n",
    "    str(onnx_path),\n",
    "    input_names=input_names,\n",
    "    output_names=[\"sentence_embedding\"],\n",
    "    dynamic_axes=dynamic_axes\n",
    ")\n",
    "\n",
    "print(\"Done. ONNX model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
